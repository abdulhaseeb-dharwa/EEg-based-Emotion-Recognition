{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'djc_eeg1', 'djc_eeg2', 'djc_eeg3', 'djc_eeg4', 'djc_eeg5', 'djc_eeg6', 'djc_eeg7', 'djc_eeg8', 'djc_eeg9', 'djc_eeg10', 'djc_eeg11', 'djc_eeg12', 'djc_eeg13', 'djc_eeg14', 'djc_eeg15'])\n",
      "[array([[-11.62290573, -16.21246338, -17.13633537, ..., -46.10419273,\n",
      "        -51.05137825, -43.6604023 ],\n",
      "       [ 14.93096352,   8.07642937,   8.19563866, ..., -24.31869507,\n",
      "        -27.74596214, -22.5007534 ],\n",
      "       [ 38.05756569,  25.57039261,  37.99796104, ..., -54.06141281,\n",
      "        -58.29334259, -48.63739014],\n",
      "       ...,\n",
      "       [ 24.25909042,  15.49720764,  21.51727676, ...,   7.62939453,\n",
      "         17.34495163,  -8.5234642 ],\n",
      "       [ 26.82209015,  27.77576447,  26.70288086, ...,  25.74920654,\n",
      "         35.76278687,  16.00384712],\n",
      "       [ 29.77252007,  33.55741501,  30.39836884, ...,  20.02716064,\n",
      "         30.15995026,  12.15934753]]), array([[-57.6376915 , -41.15700722, -41.45503044, ..., -16.65949821,\n",
      "        -28.58042717, -35.04753113],\n",
      "       [-20.17617226,  -6.34789467,  -7.95722008, ...,  13.41104507,\n",
      "          2.47359276,  -3.87430191],\n",
      "       [-14.09649849,   2.41398811,  -3.96370888, ...,  -9.41753387,\n",
      "        -17.13633537, -32.27591515],\n",
      "       ...,\n",
      "       [ -1.22189522,   3.84449959,   2.47359276, ...,  14.03689384,\n",
      "         23.51403236,  22.11332321],\n",
      "       [  8.7916851 ,  15.22898674,  12.45737076, ...,  12.27855682,\n",
      "         18.86487007,  17.55356789],\n",
      "       [  8.31484795,  12.30835915,  13.73887062, ...,  -7.24196434,\n",
      "          0.71525574,  -2.83122063]]), array([[ -51.25999451,  -49.35264587,  -48.81620407, ...,   11.4440918 ,\n",
      "          11.4440918 ,    7.83801079],\n",
      "       [ -37.6701355 ,  -34.60049629,  -34.36207771, ...,   37.31250763,\n",
      "          38.68341446,   32.33551979],\n",
      "       [-100.76165199,  -98.07944298,  -99.59936142, ...,   21.60668373,\n",
      "          23.24581146,   11.62290573],\n",
      "       ...,\n",
      "       [ -14.72234726,  -15.55681229,  -20.62320709, ...,   20.98083496,\n",
      "          25.71940422,   30.63678741],\n",
      "       [  -7.39097595,   -3.87430191,   -8.16583633, ...,   15.437603  ,\n",
      "          18.86487007,   26.2260437 ],\n",
      "       [ -15.40780067,  -17.28534698,  -20.38478851, ...,   -0.83446503,\n",
      "           4.529953  ,   11.05666161]]), array([[-11.74211502, -14.18590546, -15.1693821 , ..., -13.94748688,\n",
      "        -17.73238182, -13.58985901],\n",
      "       [-34.60049629, -43.72000694, -41.24641418, ...,  -2.02655792,\n",
      "         -3.03983688,   1.40070915],\n",
      "       [-15.7058239 , -19.07348633, -10.22219658, ..., -16.15285873,\n",
      "        -19.49071884, -10.10298729],\n",
      "       ...,\n",
      "       [ 25.45118332,  22.97759056,  23.1564045 , ..., -20.41459084,\n",
      "        -27.56714821, -27.53734589],\n",
      "       [ 17.31514931,  18.65625381,  21.63648605, ..., -11.9805336 ,\n",
      "        -14.84155655, -18.26882362],\n",
      "       [ 20.95103264,  26.13663673,  25.27236938, ...,  -2.77161598,\n",
      "         -7.89761543,  -8.61287117]]), array([[-14.513731  , -12.54677773, -15.46740532, ..., -20.68281174,\n",
      "        -27.26912498, -28.34200859],\n",
      "       [-29.71291542, -25.77900887, -34.30247307, ...,  -5.453825  ,\n",
      "        -10.04338264, -10.93745232],\n",
      "       [  4.76837158,  -7.59959221,  -5.36441803, ...,  -9.03010368,\n",
      "        -16.15285873, -11.68251038],\n",
      "       ...,\n",
      "       [ 32.36532211,  41.24641418,  38.59400749, ...,   1.1920929 ,\n",
      "          2.68220901,   8.64267349],\n",
      "       [ 11.65270805,  22.2325325 ,  16.15285873, ...,  15.40780067,\n",
      "         15.02037048,  18.74566078],\n",
      "       [  8.91089439,  15.22898674,  13.32163811, ...,   9.65595245,\n",
      "          5.39422035,   6.43730164]]), array([[ -9.11951065,  -0.83446503,   3.81469727, ..., -25.86841583,\n",
      "        -20.98083496, -16.59989357],\n",
      "       [ 14.60313797,  24.88493919,  28.66983414, ...,  -4.11272049,\n",
      "         -2.44379044,   0.56624413],\n",
      "       [  5.57303429,  18.11981201,  22.61996269, ...,  -2.83122063,\n",
      "         -7.59959221,   7.12275505],\n",
      "       ...,\n",
      "       [-48.54798317, -42.52791405, -51.73683167, ...,  11.89112663,\n",
      "         13.32163811,  22.79877663],\n",
      "       [-43.57099533, -37.84894943, -47.08766937, ...,  11.1758709 ,\n",
      "         10.2519989 ,  16.2422657 ],\n",
      "       [-14.27531242, -12.87460327, -22.08352089, ...,   7.39097595,\n",
      "          4.41074371,  16.54028893]]), array([[-33.49781036, -37.96815872, -37.52112389, ...,  57.10124969,\n",
      "         65.14787674,  64.49222565],\n",
      "       [-19.72913742, -24.58691597, -23.99086952, ...,  15.28859138,\n",
      "         22.08352089,  22.82857895],\n",
      "       [-46.78964615, -49.05462265, -48.16055298, ...,  42.76633263,\n",
      "         47.47509956,  50.66394806],\n",
      "       ...,\n",
      "       [  2.23517418,   5.69224358,   1.37090683, ...,  15.58661461,\n",
      "         13.26203346,  -4.41074371],\n",
      "       [ -2.89082527,  -0.68545341,  -4.2617321 , ...,   0.47683716,\n",
      "         -5.1856041 , -12.30835915],\n",
      "       [ -3.12924385,  -3.4570694 ,  -5.66244125, ..., -18.80526543,\n",
      "        -24.28889275, -25.60019493]]), array([[-13.56005669, -16.09325409, -11.56330109, ..., -29.29568291,\n",
      "        -27.56714821, -38.29598427],\n",
      "       [-16.48068428, -15.73562622, -14.54353333, ..., -31.62026405,\n",
      "        -30.15995026, -40.44175148],\n",
      "       [-31.65006638, -24.2292881 , -20.62320709, ..., -12.06994057,\n",
      "        -16.09325409, -25.12335777],\n",
      "       ...,\n",
      "       [-39.42847252, -28.2227993 , -35.1369381 , ...,  10.66923141,\n",
      "         10.16259193,  -6.37769699],\n",
      "       [-37.55092621, -36.53764725, -34.15346146, ...,  11.65270805,\n",
      "         10.63942909,   7.59959221],\n",
      "       [-47.80292511, -45.95518112, -36.71646118, ...,   9.74535942,\n",
      "          8.43405724,  12.60638237]]), array([[-15.76542854, -17.19594002, -22.26233482, ..., -11.92092896,\n",
      "        -12.27855682,  -4.44054604],\n",
      "       [ -1.51991844,   1.01327896,  -1.63912773, ...,  -7.4505806 ,\n",
      "         -6.31809235,  -2.65240669],\n",
      "       [ -8.88109207,   2.23517418,   1.31130219, ..., -17.40455627,\n",
      "        -20.26557922, -18.5072422 ],\n",
      "       ...,\n",
      "       [ 61.72060966,  61.06495857,  68.48573685, ...,  21.87490463,\n",
      "         24.02067184,  27.59695053],\n",
      "       [ 43.98822784,  36.65685654,  43.18356514, ...,  17.58337021,\n",
      "         28.90825272,  19.1628933 ],\n",
      "       [ 16.86811447,   7.59959221,  15.67602158, ...,  22.41134644,\n",
      "         15.91444016,  38.50460052]]), array([[-2.53617764e+01, -1.55270100e+01, -9.89437103e+00, ...,\n",
      "         3.18288803e+01,  2.79843807e+01,  3.00705433e+01],\n",
      "       [-4.12464142e+01, -3.60906124e+01, -3.18586826e+01, ...,\n",
      "         5.69224358e+00, -1.49011612e-01, -2.98023224e-02],\n",
      "       [-2.50637531e+01, -1.90138817e+01, -1.41263008e+01, ...,\n",
      "        -2.23517418e+00, -1.20103359e+01, -9.77516174e+00],\n",
      "       ...,\n",
      "       [-2.50041485e+01, -1.91926956e+01, -2.01165676e+01, ...,\n",
      "        -3.83257866e+01, -4.24981117e+01, -5.29885292e+01],\n",
      "       [-1.69277191e+01, -7.06315041e+00, -1.15036964e+01, ...,\n",
      "        -4.74154949e+01, -4.67002392e+01, -5.56707382e+01],\n",
      "       [-1.95801258e+01, -1.83880329e+01, -1.36792660e+01, ...,\n",
      "        -3.20076942e+01, -3.24845314e+01, -4.19914722e+01]]), array([[-13.02361488, -13.38124275,  -7.48038292, ...,  -0.86426735,\n",
      "          1.40070915,   4.88758087],\n",
      "       [-45.32933235, -42.64712334, -40.88878632, ...,   4.70876694,\n",
      "         10.43081284,  13.73887062],\n",
      "       [-18.98407936, -22.44114876, -25.98762512, ...,  -4.44054604,\n",
      "         -2.74181366,  -0.50663948],\n",
      "       ...,\n",
      "       [-17.61317253, -19.90795135, -20.68281174, ..., -15.79523087,\n",
      "        -13.23223114, -22.88818359],\n",
      "       [-18.44763756, -18.53704453, -17.64297485, ...,   4.7981739 ,\n",
      "          7.21216202,  -5.00679016],\n",
      "       [ -3.33786011,  -2.29477882,  -6.10947609, ...,  -0.98347664,\n",
      "         -0.29802322, -14.33491707]]), array([[-72.24082947, -64.76044655, -63.95578384, ..., -28.66983414,\n",
      "        -28.07378769, -24.08027649],\n",
      "       [-38.14697266, -31.35204315, -32.30571747, ..., -18.44763756,\n",
      "        -18.20921898, -16.06345177],\n",
      "       [-59.78345871, -59.99207497, -54.62765694, ..., -53.73358727,\n",
      "        -48.87580872, -42.08087921],\n",
      "       ...,\n",
      "       [-14.12630081, -11.53349876, -17.73238182, ..., -11.26527786,\n",
      "        -12.18914986, -16.27206802],\n",
      "       [-11.83152199,  -5.81145287,  -7.06315041, ..., -12.66598701,\n",
      "        -24.31869507, -20.74241638],\n",
      "       [-11.74211502,  -6.07967377, -10.07318497, ..., -19.84834671,\n",
      "        -14.90116119, -18.95427704]]), array([[24.25909042, 18.86487007, 16.98732376, ..., 11.41428947,\n",
      "        12.60638237, 12.60638237],\n",
      "       [ 7.1823597 ,  3.69548798,  1.49011612, ..., 11.74211502,\n",
      "        12.01033592, 13.53025436],\n",
      "       [24.05047417, 26.10683441, 25.00414848, ..., 37.9383564 ,\n",
      "        34.66010094, 33.49781036],\n",
      "       ...,\n",
      "       [33.49781036, 26.34525299, 20.83182335, ..., -6.16908073,\n",
      "        -3.36766243,  4.88758087],\n",
      "       [23.9610672 , 19.6993351 , 19.19269562, ..., 11.95073128,\n",
      "        15.58661461, 18.44763756],\n",
      "       [18.56684685, 15.79523087, 12.33816147, ..., 17.37475395,\n",
      "        20.83182335, 20.98083496]]), array([[ 27.1499157 ,  21.1596489 ,  18.83506775, ..., -19.04368401,\n",
      "        -20.80202103, -23.72264862],\n",
      "       [  0.38743019,  -5.93066216,  -4.82797623, ..., -35.34555435,\n",
      "        -36.53764725, -38.98143768],\n",
      "       [ 19.78874207,   9.53674316,  13.47064972, ..., -13.85807991,\n",
      "        -12.7851963 ,  -9.26852226],\n",
      "       ...,\n",
      "       [ 43.77961159,  33.73622894,  36.92507744, ...,  27.62675285,\n",
      "         34.95812416,  16.18266106],\n",
      "       [ 22.82857895,  19.78874207,  18.03040504, ...,  -9.1791153 ,\n",
      "         -3.33786011, -14.27531242],\n",
      "       [ 29.98113632,  24.61671829,  30.66658974, ...,  27.47774124,\n",
      "         24.70612526,  21.18945122]]), array([[ -7.95722008,  -9.08970833,  -4.14252281, ..., -10.2519989 ,\n",
      "         -7.86781311, -12.18914986],\n",
      "       [-18.03040504, -18.32842827, -20.26557922, ..., -15.05017281,\n",
      "        -14.90116119, -17.13633537],\n",
      "       [  4.50015068,   0.        ,  -5.48362732, ..., -16.57009125,\n",
      "        -17.61317253, -16.15285873],\n",
      "       ...,\n",
      "       [ 10.43081284,   7.00354576,  -1.66893005, ...,   3.93390656,\n",
      "          6.73532486,   3.90410423],\n",
      "       [ 11.11626625,   6.58631325,   0.14901161, ...,  -1.31130219,\n",
      "         -0.92387199,   8.31484795],\n",
      "       [ 11.4440918 ,   7.03334808,   2.11596489, ..., -16.45088196,\n",
      "        -17.07673073,  -5.03659248]])]\n",
      "djc_eeg1 shape: (62, 47001)\n",
      "djc_eeg2 shape: (62, 46601)\n",
      "djc_eeg3 shape: (62, 41201)\n",
      "djc_eeg4 shape: (62, 47601)\n",
      "djc_eeg5 shape: (62, 37001)\n",
      "djc_eeg6 shape: (62, 39001)\n",
      "djc_eeg7 shape: (62, 47401)\n",
      "djc_eeg8 shape: (62, 43201)\n",
      "djc_eeg9 shape: (62, 53001)\n",
      "djc_eeg10 shape: (62, 47401)\n",
      "djc_eeg11 shape: (62, 47001)\n",
      "djc_eeg12 shape: (62, 46601)\n",
      "djc_eeg13 shape: (62, 47001)\n",
      "djc_eeg14 shape: (62, 47601)\n",
      "djc_eeg15 shape: (62, 41201)\n"
     ]
    }
   ],
   "source": [
    "#Load the .mat file\n",
    "data = scipy.io.loadmat('./SEED/SEED_EEG/Preprocessed_EEG/1_20131027.mat')\n",
    "\n",
    "#Extrct EEg data and labels\n",
    "eeg_segments = [data[f'djc_eeg{i}'] for i in range(1, 16)]\n",
    "# labels = data['labels'].flatten()\n",
    "\n",
    "#convert to numpy arrays for processing \n",
    "# eeg_data = np.stack(eeg_segments, axis=0)\n",
    "print(data.keys())\n",
    "print(eeg_segments)\n",
    "for i, eeg in enumerate(eeg_segments, start=1):\n",
    "    print(f\"djc_eeg{i} shape: {eeg.shape}\")\n",
    "\n",
    "# print(labels)\n",
    "# print(f\"EEG Data shape: {eeg_data.shape}\")\n",
    "# print(f\"Labels Shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest trial length: 37001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = './SEED/SEED_EEG/Preprocessed_EEG'\n",
    "\n",
    "# Initialize variables\n",
    "all_files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
    "smallest_length = float('inf')\n",
    "\n",
    "# Step 1: Find the smallest trial length\n",
    "for file_name in all_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    # Iterate through trials in the file\n",
    "    for i in range(1, 16):\n",
    "        key = f'djc_eeg{i}'\n",
    "        if key in data:\n",
    "            trial = data[key]\n",
    "            smallest_length = min(smallest_length, trial.shape[1])\n",
    "        \n",
    "print(f\"Smallest trial length: {smallest_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Function to resample a trial to a fixed length\n",
    "def resample_trial(trial, target_length):\n",
    "    channels, time_points = trial.shape\n",
    "    resampled = np.zeros((channels, target_length))\n",
    "    for ch in range(channels):\n",
    "        interp = interp1d(np.linspace(0,1,time_points), trial[ch,:], kind='linear') \n",
    "        resampled[ch,:] = interp(np.linspace(0,1,target_length))\n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_eeg(data):\n",
    "    mean = np.mean(data, axis=(0,2), keepdims=True)\n",
    "    std = np.std(data, axis=(0,2), keepdims=True)\n",
    "    return (data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data shape: (45, 62, 37001)\n",
      "Final Labels shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for resampled and normalized data\n",
    "all_data, all_labels = [], []\n",
    "all_files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
    "for file_name in all_files:\n",
    "    data = scipy.io.loadmat(os.path.join(folder_path, file_name))\n",
    "    labels = np.array([1, 0, -1, -1, 0, 1, -1, 0, 1, 1, 0, -1, 0, 1, -1])\n",
    "    for i in range(1, 16):\n",
    "        key = f'djc_eeg{i}'\n",
    "        if key in data:\n",
    "            trial = data[key]\n",
    "            resampled = resample_trial(trial, smallest_length)\n",
    "            all_data.append(resampled)\n",
    "            all_labels.append(labels[i - 1])\n",
    "all_data = np.stack(all_data, axis=0)\n",
    "all_data = normalize_eeg(all_data)\n",
    "all_labels = np.array(all_labels)\n",
    "    \n",
    "print(f\"Final Data shape: {all_data.shape}\")\n",
    "print(f\"Final Labels shape: {all_labels.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Data Shape: (45, 62, 37001), Labels Shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Find smallest trial length\n",
    "def find_smallest_length(folder_path):\n",
    "    smallest_length = float('inf')\n",
    "    all_files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
    "    for file_name in all_files:\n",
    "        data = scipy.io.loadmat(os.path.join(folder_path, file_name))\n",
    "        for i in range(1, 16):\n",
    "            key = f'djc_eeg{i}'\n",
    "            if key in data:\n",
    "                trial = data[key]\n",
    "                smallest_length = min(smallest_length, trial.shape[1])\n",
    "    return smallest_length\n",
    "\n",
    "# Resample trials\n",
    "def resample_trial(trial, target_length):\n",
    "    channels, time_points = trial.shape\n",
    "    resampled = np.zeros((channels, target_length))\n",
    "    for ch in range(channels):\n",
    "        interp = interp1d(np.linspace(0, 1, time_points), trial[ch, :], kind='linear')\n",
    "        resampled[ch, :] = interp(np.linspace(0, 1, target_length))\n",
    "    return resampled\n",
    "\n",
    "# Stratified normalization\n",
    "def stratified_normalization(data):\n",
    "    mean = np.mean(data, axis=(0, 2), keepdims=True)\n",
    "    std = np.std(data, axis=(0, 2), keepdims=True)\n",
    "    return (data - mean) / std\n",
    "\n",
    "# Prepare data\n",
    "def prepare_data(folder_path, target_length):\n",
    "    all_data, all_labels = [], []\n",
    "    all_files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
    "    for file_name in all_files:\n",
    "        data = scipy.io.loadmat(os.path.join(folder_path, file_name))\n",
    "        labels = np.array([1, 0, -1, -1, 0, 1, -1, 0, 1, 1, 0, -1, 0, 1, -1])\n",
    "        for i in range(1, 16):\n",
    "            key = f'djc_eeg{i}'\n",
    "            if key in data:\n",
    "                trial = data[key]\n",
    "                resampled = resample_trial(trial, target_length)\n",
    "                all_data.append(resampled)\n",
    "                all_labels.append(labels[i - 1])\n",
    "    all_data = np.stack(all_data, axis=0)\n",
    "    all_data = stratified_normalization(all_data)\n",
    "    return all_data, np.array(all_labels)\n",
    "\n",
    "# Main processing\n",
    "folder_path = './SEED/SEED_EEG/Preprocessed_EEG'\n",
    "smallest_length = find_smallest_length(folder_path)\n",
    "all_data, all_labels = prepare_data(folder_path, smallest_length)\n",
    "print(f\"Prepared Data Shape: {all_data.shape}, Labels Shape: {all_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Data Shape: (495, 62, 6000), Sampled Labels Shape: (495,)\n"
     ]
    }
   ],
   "source": [
    "def sample_segments(data, labels, time_length=30 * 200, time_step=15 * 200):\n",
    "    segments, segment_labels = [], []\n",
    "    for trial, label in zip(data, labels):\n",
    "        trial_length = trial.shape[-1]\n",
    "        for start in range(0, trial_length - time_length + 1, time_step):\n",
    "            segment = trial[:, start:start + time_length]\n",
    "            segments.append(segment)\n",
    "            segment_labels.append(label)\n",
    "    return np.array(segments), np.array(segment_labels)\n",
    "\n",
    "time_length = 30 * 200  # 30 seconds * 200 Hz\n",
    "time_step = 15 * 200    # 15 seconds * 200 Hz\n",
    "sampled_data, sampled_labels = sample_segments(all_data, all_labels)\n",
    "print(f\"Sampled Data Shape: {sampled_data.shape}, Sampled Labels Shape: {sampled_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BaseEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, spatial_filters=16, temporal_filters=16):\n",
    "        super(BaseEncoder, self).__init__()\n",
    "        self.spatial_conv = nn.Conv1d(input_channels, spatial_filters, kernel_size=1)\n",
    "        self.temporal_conv = nn.Conv1d(spatial_filters, temporal_filters, kernel_size=60, padding=30)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)  # Pool across the time dimension\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.spatial_conv(x))  # Spatial convolution\n",
    "        x = self.relu(self.temporal_conv(x))  # Temporal convolution\n",
    "        x = self.avg_pool(x).squeeze(-1)  # Reduce time dimension\n",
    "        return x  # Shape: [batch_size, temporal_filters]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projector(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=64):\n",
    "        super(Projector, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)  # Shape: [batch_size, latent_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, input_channels, temporal_filters, latent_dim=64):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.encoder = BaseEncoder(input_channels, temporal_filters=temporal_filters)\n",
    "        self.projector = Projector(input_dim=temporal_filters, latent_dim=latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)  # Shape: [batch_size, temporal_filters]\n",
    "        projected = self.projector(encoded)  # Shape: [batch_size, latent_dim]\n",
    "        return projected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_8984\\1233950057.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_A = torch.tensor(batch_A, dtype=torch.float32)  # Shape: [batch_size, channels, time_points]\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_8984\\1233950057.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_B = torch.tensor(batch_B, dtype=torch.float32)  # Shape: [batch_size, channels, time_points]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_A Shape: torch.Size([32, 64]), z_B Shape: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "contrastive_model = ContrastiveModel(input_channels=sampled_data.shape[1],temporal_filters=16, latent_dim=64)\n",
    "\n",
    "batch_A = torch.tensor(batch_A, dtype=torch.float32)  # Shape: [batch_size, channels, time_points]\n",
    "batch_B = torch.tensor(batch_B, dtype=torch.float32)  # Shape: [batch_size, channels, time_points]\n",
    "\n",
    "z_A = contrastive_model(batch_A)  # Shape: [batch_size, latent_dim]\n",
    "z_B = contrastive_model(batch_B)  # Shape: [batch_size, latent_dim]\n",
    "\n",
    "print(f\"z_A Shape: {z_A.shape}, z_B Shape: {z_B.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_loss(z_i, z_j, temperature=0.5):\n",
    "    z_i = F.normalize(z_i, dim=1)\n",
    "    z_j = F.normalize(z_j, dim=1)\n",
    "    similarity_matrix = torch.matmul(z_i, z_j.T) / temperature\n",
    "    labels = torch.arange(z_i.size(0)).to(z_i.device)\n",
    "    return F.cross_entropy(similarity_matrix, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1, Loss: 3.4478\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "input_channels = sampled_data.shape[1]\n",
    "temporal_filters = 16  # Match the `temporal_filters` in the encoder\n",
    "latent_dim = 64\n",
    "\n",
    "contrastive_model = ContrastiveModel(input_channels=input_channels, temporal_filters=temporal_filters, latent_dim=latent_dim).tp(device)\n",
    "optimizer = torch.optim.Adam(contrastive_model.parameters(), lr=0.0007, weight_decay=0.015)\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    contrastive_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Generate minibatches\n",
    "    batch_A, batch_B = data_sampler(sampled_data, sampled_labels)  # Shape: [batch_size, channels, time_points]\n",
    "    batch_A = torch.tensor(batch_A, dtype=torch.float32).to(device)\n",
    "    batch_B = torch.tensor(batch_B, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    z_A = contrastive_model(batch_A)  # Shape: [batch_size, latent_dim]\n",
    "    z_B = contrastive_model(batch_B)  # Shape: [batch_size, latent_dim]\n",
    "\n",
    "    # Compute contrastive loss\n",
    "    loss = contrastive_loss(z_A, z_B)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n",
    "    \n",
    "plt.plot(losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Contrastive Learning Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch A Shape: torch.Size([32, 62, 6000])\n",
      "Encoder Output Shape: torch.Size([32, 64])\n",
      "Contrastive Loss Input Shapes: z_A=torch.Size([32, 64]), z_B=torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Batch A Shape: {batch_A.shape}\")  # Expected: [batch_size, channels, time_points]\n",
    "print(f\"Encoder Output Shape: {z_A.shape}\")  # Expected: [batch_size, latent_dim]\n",
    "print(f\"Contrastive Loss Input Shapes: z_A={z_A.shape}, z_B={z_B.shape}\")  # Expected: [batch_size, latent_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "# Assuming `de_features_test` are the DE features for the test set\n",
    "# and `labels_test` are the ground truth labels for the test set\n",
    "classifier = EmotionClassifier(input_dim=64, num_classes=3).to(device)\n",
    "\n",
    "# Evaluate on test set\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    logits = classifier(torch.tensor(de_features_test, dtype=torch.float32).to(device))\n",
    "    predictions = torch.argmax(logits, axis=1).cpu().numpy()  # Move to CPU for evaluation\n",
    "    labels_test = labels_test.cpu().numpy()  # Ensure labels are also on CPU\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(labels_test, predictions, labels=[-1, 0, 1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(labels_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot training loss\n",
    "axes[0].plot(losses, label=\"Training Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Contrastive Learning Training Loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(ax=axes[1], cmap=plt.cm.Blues, colorbar=False)\n",
    "axes[1].set_title(\"Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
