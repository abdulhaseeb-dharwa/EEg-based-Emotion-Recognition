{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 2 Using better ICA Gpu Rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-09 16:38:00] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record _record_0...\n",
      "Applying GPU-accelerated 0.05–47 Hz bandpass filter for record _record_0...\n",
      "Applying Infomax ICA for artifact removal on record _record_0...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No EOG channel(s) found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 104\u001b[0m\n\u001b[0;32m     98\u001b[0m ica\u001b[38;5;241m.\u001b[39mfit(raw, picks\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Automatically Detect and Limit Exclusions to 2 Worst Components\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Detect EOG artifacts\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m eog_indices, eog_scores \u001b[38;5;241m=\u001b[39m \u001b[43mica\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_bads_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOG components identified: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meog_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Detect muscle artifacts\u001b[39;00m\n",
      "File \u001b[1;32m<decorator-gen-354>:12\u001b[0m, in \u001b[0;36mfind_bads_eog\u001b[1;34m(self, inst, ch_name, threshold, start, stop, l_freq, h_freq, reject_by_annotation, measure, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\mne\\preprocessing\\ica.py:2116\u001b[0m, in \u001b[0;36mICA.find_bads_eog\u001b[1;34m(self, inst, ch_name, threshold, start, stop, l_freq, h_freq, reject_by_annotation, measure, verbose)\u001b[0m\n\u001b[0;32m   2113\u001b[0m _validate_type(measure, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2114\u001b[0m _check_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m\"\u001b[39m, measure, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrelation\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 2116\u001b[0m eog_inds \u001b[38;5;241m=\u001b[39m \u001b[43m_get_eog_channel_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2117\u001b[0m eog_chs \u001b[38;5;241m=\u001b[39m [inst\u001b[38;5;241m.\u001b[39mch_names[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m eog_inds]\n\u001b[0;32m   2119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m measure \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzscore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tahir\\Documents\\EEg-based-Emotion-Recognition\\.venv\\Lib\\site-packages\\mne\\preprocessing\\eog.py:203\u001b[0m, in \u001b[0;36m_get_eog_channel_index\u001b[1;34m(ch_name, inst)\u001b[0m\n\u001b[0;32m    191\u001b[0m     eog_inds \u001b[38;5;241m=\u001b[39m pick_types(\n\u001b[0;32m    192\u001b[0m         inst\u001b[38;5;241m.\u001b[39minfo,\n\u001b[0;32m    193\u001b[0m         meg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m         exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m     )\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eog_inds\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo EOG channel(s) found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    204\u001b[0m     ch_names \u001b[38;5;241m=\u001b[39m [inst\u001b[38;5;241m.\u001b[39mch_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m eog_inds]\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ch_name, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No EOG channel(s) found"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from torcheeg.datasets import SEEDDataset\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load the SEED Dataset\n",
    "# ---------------------------------------------------------------\n",
    "dataset = SEEDDataset(\n",
    "    io_path='C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS',\n",
    "    online_transform=None,\n",
    "    label_transform=None,\n",
    "    num_worker=6\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Directory to Save the Cleaned Data\n",
    "# ---------------------------------------------------------------\n",
    "save_dir = 'C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/cleaned_data'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Group Samples by Record ID\n",
    "# ---------------------------------------------------------------\n",
    "record_groups = defaultdict(list)\n",
    "\n",
    "for idx in range(len(dataset)):\n",
    "    eeg_data, label = dataset[idx]\n",
    "    record_id = label['_record_id']\n",
    "    record_groups[record_id].append(eeg_data)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Process Each Unique Record\n",
    "# ---------------------------------------------------------------\n",
    "for record_id, eeg_samples in record_groups.items():\n",
    "    print(f\"Processing record {record_id}...\")\n",
    "\n",
    "    # Concatenate all samples within the record along the time axis\n",
    "    eeg_data = np.hstack(eeg_samples)  # Shape: (channels, combined_time_points)\n",
    "\n",
    "    # Create MNE info object\n",
    "    sfreq = 200  # Original sampling frequency (200 Hz)\n",
    "    ch_names = [f'Ch{i+1}' for i in range(eeg_data.shape[0])]\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=['eeg'] * len(ch_names))\n",
    "\n",
    "    # Create MNE Raw object\n",
    "    raw = mne.io.RawArray(eeg_data, info)\n",
    "\n",
    "    # Assign a standard montage\n",
    "    montage = mne.channels.make_standard_montage('standard_1005')\n",
    "    raw.rename_channels({f'Ch{i+1}': montage.ch_names[i] for i in range(len(ch_names))})\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Preprocessing: Bandpass Filter (0.05–47 Hz) and Downsampling\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(f\"Applying 0.05–47 Hz bandpass filter for record {record_id}...\")\n",
    "    raw.filter(l_freq=0.05, h_freq=47.0, fir_design='firwin')\n",
    "\n",
    "    # Downsample to 100 Hz to speed up ICA\n",
    "    print(f\"Downsampling to 100 Hz for record {record_id}...\")\n",
    "    raw.resample(sfreq=100)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Apply ICA for Artifact Removal (Infomax)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(f\"Applying Infomax ICA for artifact removal on record {record_id}...\")\n",
    "\n",
    "    # Set ICA parameters to use Infomax with a reduced number of components\n",
    "    ica = mne.preprocessing.ICA(\n",
    "        n_components=len(ch_names) - 1, # Limit to 30 components for faster processing\n",
    "        method='infomax',      # Use Infomax algorithm as specified in the paper\n",
    "        max_iter=200,          # Default max_iter\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit ICA to the data\n",
    "    ica.fit(raw, picks='all')\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Automatically Detect and Limit Exclusions to 2 Worst Components\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Define virtual EOG channels (frontal electrodes)\n",
    "    eog_virtual_channels = ['Fp1', 'Fp2']\n",
    "\n",
    "    try:\n",
    "        # Detect EOG artifacts using virtual EOG channels\n",
    "        eog_indices, eog_scores = ica.find_bads_eog(raw, ch_name=eog_virtual_channels)\n",
    "        print(f\"EOG components identified: {eog_indices}\")\n",
    "    except RuntimeError:\n",
    "        print(\"No suitable EOG channels found. Skipping EOG artifact detection.\")\n",
    "        eog_indices, eog_scores = [], []\n",
    "\n",
    "    # Detect muscle artifacts\n",
    "    muscle_indices, muscle_scores = ica.find_bads_muscle(raw)\n",
    "    print(f\"Muscle artifact components identified: {muscle_indices}\")\n",
    "\n",
    "    # Combine indices and scores\n",
    "    all_indices = eog_indices + muscle_indices\n",
    "    all_scores = eog_scores + muscle_scores\n",
    "\n",
    "    # Limit to the 2 worst components (highest scores)\n",
    "    if len(all_indices) > 2:\n",
    "        worst_indices = [idx for _, idx in sorted(zip(all_scores, all_indices), key=lambda x: x[0], reverse=True)[:2]]\n",
    "    else:\n",
    "        worst_indices = all_indices\n",
    "\n",
    "    # Set components to exclude\n",
    "    ica.exclude = worst_indices\n",
    "    print(f\"Excluded components for record {record_id}: {ica.exclude}\")\n",
    "\n",
    "    # Apply ICA to remove the selected components\n",
    "    ica.apply(raw)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Save the Cleaned Data\n",
    "    # -------------------------------------------------------------------------\n",
    "    save_path = os.path.join(save_dir, f'cleaned_{record_id}.fif')\n",
    "    raw.save(save_path, overwrite=True)\n",
    "    print(f\"Processed and saved record {record_id} to {save_path}\")\n",
    "\n",
    "print(\"All records have been processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-09 17:02:39] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOG components identified: [0]\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from torcheeg.datasets import SEEDDataset\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load the SEED Dataset\n",
    "# ---------------------------------------------------------------\n",
    "dataset = SEEDDataset(\n",
    "    io_path='C:/Users/tahir/Documents/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS',\n",
    "    online_transform=None,\n",
    "    label_transform=None,\n",
    "    num_worker=6\n",
    ")\n",
    "\n",
    "# Load a single sample to test\n",
    "eeg_data, label = dataset[0]\n",
    "\n",
    "# Create MNE info object\n",
    "sfreq = 200  # Sampling frequency (200 Hz)\n",
    "ch_names = [f'Ch{i+1}' for i in range(eeg_data.shape[0])]\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=['eeg'] * len(ch_names))\n",
    "\n",
    "# Create MNE Raw object\n",
    "raw = mne.io.RawArray(eeg_data, info)\n",
    "\n",
    "# Assign a standard montage\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "raw.rename_channels({f'Ch{i+1}': montage.ch_names[i] for i in range(len(ch_names))})\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# Apply bandpass filtering (0.05–47 Hz)\n",
    "raw.filter(l_freq=0.05, h_freq=47.0, fir_design='firwin')\n",
    "\n",
    "# Create ICA object with fewer components and fit on a small subset of data\n",
    "ica = mne.preprocessing.ICA(\n",
    "    n_components=20,       # Use fewer components to speed up the process\n",
    "    method='infomax',\n",
    "    max_iter=100,          # Reduce iterations for quicker fitting\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit ICA on the available duration of data\n",
    "raw_subset = raw.copy().crop(tmin=0, tmax=raw.times[-1])\n",
    "ica.fit(raw_subset, picks='all')\n",
    "\n",
    "# Check virtual EOG channels\n",
    "eog_virtual_channels = ['Fp1', 'Fp2']  # Adjust based on your montage\n",
    "\n",
    "try:\n",
    "    # Attempt to find EOG artifacts\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(raw_subset, ch_name=eog_virtual_channels)\n",
    "    print(f\"EOG components identified: {eog_indices}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
