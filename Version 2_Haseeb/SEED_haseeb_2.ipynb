{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-06 18:10:06] INFO (torcheeg/MainThread) üîç | Detected cached processing results, reading cache from D:/FAST/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS.\n"
     ]
    }
   ],
   "source": [
    "from torcheeg.datasets import SEEDDataset\n",
    "from torcheeg import transforms\n",
    "raw_dataset = SEEDDataset(\n",
    "    root_path='D:/FAST/EEg-based-Emotion-Recognition/Preprocessed_EEG',\n",
    "    io_path='D:/FAST/EEg-based-Emotion-Recognition/.torcheeg/datasets_1733174610032_5iJyS',\n",
    "    online_transform=None,\n",
    "    label_transform=None,\n",
    "    num_worker=4\n",
    ")\n",
    "\n",
    "raw_sample = raw_dataset[0]\n",
    "print(f\"Raw EEG data shape: {raw_sample[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torcheeg.utils import plot_2d_tensor\n",
    "\n",
    "img = plot_2d_tensor(torch.tensor(raw_sample[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.model_selection import LeaveOneSubjectOut\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(f\"Dataset contains {len(raw_dataset)} samples.\")\n",
    "print(f\"Dataset size: {len(raw_sample)}\")\n",
    "print(f\"Sample format: {raw_dataset[0]}\")  # Check a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(raw_dataset):\n",
    "    assert sample[0].shape == (62, 200), f\"Mismatch at sample {i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Organize data by emotion classes\n",
    "emotion_classes = defaultdict(list)\n",
    "for sample, metadata in raw_dataset:\n",
    "    emotion = metadata['emotion']  # Assume emotion: -1 (negative), 0 (neutral), 1 (positive)\n",
    "    emotion_classes[emotion].append((sample, metadata))\n",
    "    \n",
    "print({emotion: len(samples) for emotion, samples in emotion_classes.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Define bandpass filter\n",
    "def bandpass_filter(data, lowcut=4, highcut=47, fs=200, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return lfilter(b, a, data, axis=-1)\n",
    "\n",
    "# Apply bandpass filter to dataset\n",
    "def filter_dataset(dataset, lowcut=4, highcut=47, fs=200):\n",
    "    filtered_dataset = []\n",
    "    for sample, metadata in dataset:\n",
    "        filtered_sample = bandpass_filter(sample, lowcut, highcut, fs)\n",
    "        filtered_dataset.append((filtered_sample, metadata))\n",
    "    return filtered_dataset\n",
    "\n",
    "filtered_dataset = filter_dataset(raw_dataset)\n",
    "print(len(filtered_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torcheeg.utils import plot_2d_tensor\n",
    "\n",
    "print(filtered_dataset[0][0].shape)\n",
    "\n",
    "img = plot_2d_tensor(torch.tensor(filtered_dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Function to process a single sample with ICA\n",
    "def process_sample_with_ica(args):\n",
    "    sample, metadata, fs, n_components, max_iter = args\n",
    "    try:\n",
    "        # Create MNE Info object\n",
    "        info = mne.create_info(\n",
    "            ch_names=[f'ch_{i}' for i in range(sample.shape[0])],\n",
    "            sfreq=fs, \n",
    "            ch_types='eeg'\n",
    "        )\n",
    "        raw = mne.io.RawArray(sample, info)\n",
    "\n",
    "        # Fit ICA with reduced components and higher max_iter\n",
    "        ica = mne.preprocessing.ICA(n_components=n_components, random_state=42, max_iter=max_iter)\n",
    "        print(f\"Fitting ICA for sample with metadata: {metadata}\")\n",
    "        ica.fit(raw)\n",
    "\n",
    "        # Apply ICA to remove artifacts\n",
    "        print(f\"Applying ICA for sample with metadata: {metadata}\")\n",
    "        raw_cleaned = ica.apply(raw)\n",
    "\n",
    "        # Return cleaned data and metadata\n",
    "        return raw_cleaned.get_data(), metadata\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e} for sample with metadata: {metadata}. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e} for sample with metadata: {metadata}. Skipping...\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for batch processing with parallelization\n",
    "def parallel_process_ica(dataset, fs=200, n_components=28, max_iter=2000, batch_size=50, num_workers=4):\n",
    "    cleaned_dataset = []\n",
    "    print(f\"Starting ICA processing with n_components={n_components}, max_iter={max_iter}, batch_size={batch_size}, num_workers={num_workers}...\")\n",
    "\n",
    "    # Process the dataset in batches\n",
    "    for start in range(0, len(dataset), batch_size):\n",
    "        end = min(start + batch_size, len(dataset))\n",
    "        batch = dataset[start:end]\n",
    "        print(f\"Processing batch {start // batch_size + 1} with {len(batch)} samples...\")\n",
    "\n",
    "        # Prepare arguments for parallel processing\n",
    "        args = [(sample, metadata, fs, n_components, max_iter) for sample, metadata in batch]\n",
    "\n",
    "        # Use multiprocessing to parallelize ICA across CPU cores\n",
    "        with Pool(num_workers) as p:\n",
    "            results = p.map(process_sample_with_ica, args)\n",
    "\n",
    "        # Collect cleaned data, ignoring failed samples\n",
    "        cleaned_dataset.extend([result for result in results if result is not None])\n",
    "\n",
    "    print(\"ICA processing completed.\")\n",
    "    return cleaned_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to the dataset with optimizations\n",
    "cleaned_dataset = parallel_process_ica(\n",
    "    filtered_dataset,\n",
    "    fs=200,\n",
    "    n_components=28,\n",
    "    max_iter=800,\n",
    "    batch_size=50,\n",
    "    num_workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def re_reference_to_average(dataset):\n",
    "    re_referenced_dataset = []\n",
    "    for sample, metadata in dataset:\n",
    "        # Subtract the average of all channels\n",
    "        mean_channel = np.mean(sample, axis=0, keepdims=True)\n",
    "        re_referenced_sample = sample - mean_channel\n",
    "        re_referenced_dataset.append((re_referenced_sample, metadata))\n",
    "    return re_referenced_dataset\n",
    "\n",
    "re_referenced_dataset = re_reference_to_average(cleaned_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(dataset, epoch_length=6000, step_size=3000):\n",
    "    segmented_dataset = []\n",
    "    for sample, metadata in dataset:\n",
    "        num_points = sample.shape[1]\n",
    "        for start in range(0, num_points - epoch_length + 1, step_size):\n",
    "            segment = sample[:, start:start + epoch_length]\n",
    "            segmented_dataset.append((segment, metadata))\n",
    "    return segmented_dataset\n",
    "\n",
    "segmented_dataset = segment_data(re_referenced_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
